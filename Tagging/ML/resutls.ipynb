{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "DICT_SIZE=15000\n",
    "with open('/home/adithya/Desktop/mybag_vectorizer','rb') as f:\n",
    "    model=pickle.load(f)\n",
    "with open('/home/adithya/Desktop/WORDS_TO_INDEX','rb') as f:\n",
    "   WORDS_TO_INDEX=pickle.load(f)\n",
    "with open('/home/adithya/Desktop/mlb','rb') as f:\n",
    "    mlb=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    \n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text.split():\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] += 1\n",
    "    \n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bagpredict(text):\n",
    "    text=text[0]\n",
    "    from scipy import sparse as sp_sparse\n",
    "#     text='Load Machine Learning sklearn models (RandomForestClassifier) through java and send as argument to a function in python file'\n",
    "    ptext = sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE))\n",
    "    predicted = model.predict(ptext)\n",
    "    final = mlb.inverse_transform(predicted)\n",
    "    return(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/adithya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/adithya/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/adithya/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Now multi neural\n",
    "\n",
    "with open('/home/adithya/Desktop/tokenize','rb') as f:\n",
    "    tokenize=pickle.load(f)\n",
    "with open('/home/adithya/Desktop/Nmodel','rb') as f:\n",
    "    Nmodel=pickle.load(f)\n",
    "with open('/home/adithya/Desktop/text_labels','rb') as f:\n",
    "    text_labels=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nmodelpredict(text):\n",
    "# text=['Load Machine Learning sklearn models (RandomForestClassifier) through java and send as argument to a function in python file']\n",
    "    yes = tokenize.texts_to_matrix(text)\n",
    "    prediction = Nmodel.predict(np.array(yes))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]\n",
    "    return(predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/adithya/Desktop/gtokenize','rb') as f:\n",
    "    gtokenize=pickle.load(f)\n",
    "with open('/home/adithya/Desktop/gNmodel','rb') as f:\n",
    "    gNmodel=pickle.load(f)\n",
    "with open('/home/adithya/Desktop/gtext_labels','rb') as f:\n",
    "    gtext_labels=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gNmodelpredict(text):   \n",
    "#     text=['Load Machine Learning sklearn models (RandomForestClassifier) through java and send as argument to a function in python file']\n",
    "    yes = gtokenize.texts_to_matrix(text)\n",
    "    prediction = gNmodel.predict(np.array(yes))\n",
    "    predicted_label = gtext_labels[np.argmax(prediction)]\n",
    "    return(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gNmodelpredict    python\n",
      "Nmodelpredict    ['python', 'pandas']\n",
      "Bagpredict    [('pandas', 'python')]\n"
     ]
    }
   ],
   "source": [
    "text=['Form pandas series of elements by taking dictionary as a input wherein value indicates frequency of key in that dictionary']\n",
    "predicted=gNmodelpredict(text)\n",
    "print('gNmodelpredict   ',predicted)\n",
    "predicted=Nmodelpredict(text)\n",
    "print('Nmodelpredict   ',predicted)\n",
    "predicted=Bagpredict(text)\n",
    "print('Bagpredict   ',predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
